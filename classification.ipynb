{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from datasets import load_dataset\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_train = 'scicite/train.jsonl'\n",
    "file_path_dev = 'scicite/dev.jsonl'\n",
    "file_path_test = 'scicite/test.jsonl'\n",
    "train_data = []\n",
    "dev_data = []\n",
    "test_data = []\n",
    "with open(file_path_train, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        train_data.append(json.loads(line))\n",
    "with open(file_path_dev, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        dev_data.append(json.loads(line))\n",
    "with open(file_path_test, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        test_data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CitationsDatasetWithoutInputExample():\n",
    "    label_to_id = {'background': 0, 'method': 1, 'result': 2}\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]['string'], CitationsDatasetWithoutInputExample.label_to_id[self.data[item]['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CitationsDatasetWithoutInputExample(train_data)\n",
    "train_batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = CitationsDatasetWithoutInputExample(dev_data)\n",
    "dev_batch_size = 16\n",
    "dev_dataloader = DataLoader(dev_dataset, shuffle=False, batch_size=dev_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CitationIntentEncoder(nn.Module):\n",
    "    def __init__(self, sciBert):\n",
    "        super(CitationIntentEncoder, self).__init__()\n",
    "        self.sentence_transformer = sciBert\n",
    "        self.dense = nn.Linear(768, 768)\n",
    "        self.activation = nn.Tanh()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        embeddings = self.sentence_transformer(input_ids, attention_mask)\n",
    "        cls_representation = embeddings.last_hidden_state[:, 0]\n",
    "        x = self.dense(cls_representation)\n",
    "        return self.activation(x)\n",
    "\n",
    "def load_CLModel(save_directory):\n",
    "    # Load trained model\n",
    "    config = AutoConfig.from_pretrained(save_directory)\n",
    "    sciBert = AutoModel.from_config(config)\n",
    "    CL_model = CitationIntentEncoder(sciBert)\n",
    "\n",
    "    CL_model.load_state_dict(torch.load(save_directory + '/CLModel_state_dict.bin'))\n",
    "    return CL_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CitationIntentClassifier(nn.Module):\n",
    "    def __init__(self, model_path, num_labels):\n",
    "        super(CitationIntentClassifier, self).__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
    "        self.sentence_transformer = load_CLModel(model_path)\n",
    "        self.classifier = nn.Linear(768, num_labels)\n",
    "\n",
    "    def forward(self, input_texts):\n",
    "        tokenised = self.tokenizer(input_texts, return_tensors='pt', truncation=True, padding='max_length', max_length=256)        \n",
    "        embeddings = self.sentence_transformer(input_ids=tokenised['input_ids'], attention_mask=tokenised['attention_mask'])\n",
    "        return self.classifier(embeddings)\n",
    "\n",
    "def train_epoch(model, dataloader, loss_func, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for input_texts, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_texts)\n",
    "        loss = loss_func(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    print(f\"Training loss: {total_loss / len(dataloader)}\")\n",
    "\n",
    "def evaluate(model, dataloader, loss_func):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for input_texts, labels in dataloader:\n",
    "            output = model(input_texts)\n",
    "            loss = loss_func(output, labels)\n",
    "            total_loss += loss.item()\n",
    "            total_correct += (output.argmax(1) == labels).sum().item()\n",
    "            \n",
    "    print(f\"Evaluation loss: {total_loss / len(dataloader)}\")\n",
    "    print(f\"Evaluation accuracy: {total_correct / len(dataloader.dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CitationsDatasetWithoutInputExample(test_data)\n",
    "test_batch_size = 16\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=False, batch_size=test_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_texts, labels in dataloader:\n",
    "            output = model(input_texts)\n",
    "            _, predicted_labels = torch.max(output, dim=1)\n",
    "            predictions.extend(predicted_labels.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    return predictions, true_labels\n",
    "\n",
    "\n",
    "def train_test_loop(model_name):\n",
    "    num_labels = 3\n",
    "    citation_intent_classifier = CitationIntentClassifier(model_name, num_labels)\n",
    "\n",
    "    # Parameters\n",
    "    learning_rate = 2e-5\n",
    "    num_epochs = 5\n",
    "\n",
    "    optimizer = torch.optim.Adam(citation_intent_classifier.parameters(), lr=learning_rate)\n",
    "    loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        train_epoch(citation_intent_classifier, train_dataloader, loss_func, optimizer)\n",
    "        evaluate(citation_intent_classifier, dev_dataloader, loss_func)\n",
    "        \n",
    "    predictions, true_labels = test(citation_intent_classifier, test_dataloader)\n",
    "    f1 = f1_score(true_labels, predictions, average='macro')\n",
    "    print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "{'input_ids': tensor([[ 102,  111, 4234,  ...,    0,    0,    0],\n",
      "        [ 102,  188,  121,  ...,    0,    0,    0],\n",
      "        [ 102,  147, 2100,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 102,  190,  111,  ...,    0,    0,    0],\n",
      "        [ 102,  185, 1058,  ...,    0,    0,    0],\n",
      "        [ 102,  260, 3291,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "loss caluclated\n",
      "Training loss: 0.002158372670181038\n",
      "{'input_ids': tensor([[  102,   407,   545,  ...,     0,     0,     0],\n",
      "        [  102,   101, 10890,  ...,     0,     0,     0],\n",
      "        [  102,   238,   165,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  102,  5398,   422,  ...,     0,     0,     0],\n",
      "        [  102,  1502, 30130,  ...,     0,     0,     0],\n",
      "        [  102,  2487,  7174,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "Evaluation loss: 0.017343058668333907\n",
      "Evaluation accuracy: 0.007641921397379912\n",
      "{'input_ids': tensor([[ 102, 3953,  154,  ...,    0,    0,    0],\n",
      "        [ 102,  121,  867,  ...,    0,    0,    0],\n",
      "        [ 102, 1323, 7252,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 102,  238,  241,  ...,    0,    0,    0],\n",
      "        [ 102,  121,  993,  ...,    0,    0,    0],\n",
      "        [ 102,  260,  760,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n",
      "F1 Score: 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "train_test_loop('./sectionPaper_mlp_without_hard')\n",
    "#train_test_loop('./sectionPaper_without_hard')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
